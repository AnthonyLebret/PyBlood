# import des packages n√©cessaires √† la mod√©lisation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
import plotly_express as px

st.set_page_config(page_title="Classification", page_icon="üóÇÔ∏è")
st.sidebar.header("Classification")
st.sidebar.info("Auteur : \n\n - Anthony LEBRET [Linkedin](https://linkedin.com/in/anthony-lebret-a7aabb176)")
st.sidebar.info("Donn√©es : [Mendeley Data - A dataset for microscopic peripheral blood cell images for development of automatic recognition systems](https://data.mendeley.com/datasets/snkd93bnjr/1)")

# Cacher "Made with Streamlit"
hide_footer_style = """ 
    <style>
    footer {visibility: hidden; }
    </style>
    """
st.markdown(hide_footer_style, unsafe_allow_html=True)

# Image PyBlood
from PIL import Image
image = Image.open('data/PyBlood.jpg')
st.image(image)

# Titre
st.title("Machine Learning")

# Classification
st.header("Classification")
st.subheader("R√©duction de dimension")
st.write("Afin de pouvoir entra√Æner **plusieurs mod√®les de machine learning** sur l'ensemble des donn√©es (~17 000 images) en un temps raisonnable, j'ai opt√© pour une **r√©duction de dimension via UMAP**, qui a le double avantage de pouvoir √™tre employ√© pour des **visualisations** mais aussi pour faire des **r√©ductions non lin√©aires g√©n√©rales**. La taille des images a √©galement √©t√© r√©duite aux dimensions 256x256.")

# Import dataset
df = pd.read_csv("data/dataset.csv")
plot_df = pd.read_csv("data/plot_UMAP_2d.csv")

fig_2d = px.scatter(data_frame = plot_df, x='X_UMAP', y='Y_UMAP', color=df.classes, labels={'color': 'classes'})
fig_2d.update_traces(marker_size=2)
st.plotly_chart(fig_2d)

st.subheader("Optimisation des hyperparam√®tres")
st.write("Toujours dans une d√©marche de **diminution des temps d'ex√©cution**, les hyperparam√®tres ont √©t√© optimis√©s par une **m√©thode hybride de recherche en grille (GridSearchCV) et recherche bay√©sienne**. Cette m√©thode est g√©n√©ralement **aussi performante** qu'une optimisation par recherche en grille stricte mais est **bien plus rapide**.")
with st.expander("Afficher/Cacher le code pour l'optimisation des hyperparam√®tres"):
    st.code("""# Optimisation des param√®tres

def best_model_Ray_bayes(X_train, y_train, name, model):    
    '''run gridsearchCV pipeline with bayesian method on models
    Args:
        -model: initiated model 
        -name : name of model as str
    return list of best estimator and table of results
    '''

    best_model_stack = list()
    results_cv = dict()
    
    def grid_csv(params, early_stopping=False):

        GSCV = TuneSearchCV(model, params, 
                            search_optimization='bayesian',
                            n_trials=7,
                            early_stopping=early_stopping,
                            max_iters=10,
                            scoring = 'accuracy',
                            loggers=['csv'],
                            cv = 5, n_jobs=7, verbose=1)

        best_clf = GSCV.fit(X_train, y_train)

        best_hyperparams = best_clf.best_params_
        best_score = best_clf.best_score_
        estimator = best_clf.best_estimator_
        print(f'Mean cross-validated accuracy score of the best_estimator:{best_score:.3f}')
        print(f'with {best_hyperparams} for {estimator}')
        table = best_clf.cv_results_
        results_cv[name] = table

        return estimator
        

    if name == 'LR':
        params = {'C' : tuple([0.001, 0.01, 0.1, 1.]),
                 'penalty' : tuple(['l1', 'l2'])} 
        best_model_stack.append(grid_csv(params))
              
    if name == 'KNN':
        params = {'n_neighbors' : tuple(np.arange(5, 100, 5)),
                 'weights' : tuple(['uniform', 'distance']),
                 'algorithm' : tuple(['ball_tree', 'kd_tree', 'brute', 'auto'])} 
        best_model_stack.append(grid_csv(params))
    
    if name == 'SVM':
        params = {'kernel' : tuple(['linear', 'poly', 'rbf', 'sigmoid']),
                 'C' : tuple(np.arange(0.01, 1, 0.02))} 
        best_model_stack.append(grid_csv(params))


    if name == 'RF': 
        params = {'n_estimators' : tuple(np.arange(5, 200, 10)),
                  'max_features' : tuple(['auto', 'sqrt', 'log2']),
                  'max_depth' : tuple(np.arange(3, 15, 1)),
                  'min_weight_fraction_leaf': tuple(np.arange(0, 0.6, 0.2))
                 } 
        best_model_stack.append(grid_csv(params))

        
    return best_model_stack, results_cv""")

st.subheader("Entra√Ænement des mod√®les")
st.write("Les donn√©es **r√©duites apr√®s UMAP** ont √©t√© utilis√©es afin d'entra√Æner **4 mod√®les de classification** :")
col1, col2 = st.columns(2)
with col1:
    st.write("- **R√©gression logistique (LR)**")
    st.write("- **Algorithme des K plus proches voisins (KNN)**")
with col2:
    st.write("- **Machine √† vecteurs de support (SVM)**")
    st.write("- **Algorithme des for√™ts al√©atoires (RF)**")

st.subheader("R√©sultats")
st.markdown("#### Sur les images non-segment√©es")

st.write("L'ex√©cution de la pipeline d'entra√Ænement des mod√®les pouvant prendre **plus d'une heure**, celle-ci ne sera **pas ex√©cut√©e sur cette page**. N√©anmoins, il est int√©ressant de noter que **les scores varient de plusieurs pourcentages d'une ex√©cution √† une autre**. Cette **variabilit√©** ne semble pas √™tre induite par l'optimisation des hyperparam√®tres (ceux-ci sont relativement constants) mais vraisemblablement par **les images s√©lectionn√©es comme √©chantillons d'entra√Ænement et de test**")

st.write("**Les meilleurs scores** sont obtenus par le mod√®le de **for√™ts al√©atoires**. L'accuracy et le F1-Score sont de **0.75**. Comme attendu apr√®s visualisation de la projection UMAP, **les plaquettes sont correctement class√©es √† 95%** (F1-Score). N√©anmoins, les classes basophiles et granulocytes immatures (IG) viennent tirer le score moyen vers le bas : ils sont correctement pr√©dits √† hauteur de **59%** pour le premier et **65%** pour le second.")

rf = Image.open('streamlit/rf.png')
st.image(rf)

with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le de r√©gression logistique"):
    lr = Image.open('streamlit/lr.png')
    st.image(lr)
with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le des K plus proches voisins"):
    knn = Image.open('streamlit/knn.png')
    st.image(knn)
with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le SVM"):
    svm = Image.open('streamlit/svm.png')
    st.image(svm)

st.markdown("#### Sur les images segment√©es")

st.write("A la diff√©rence des scores sur les images brutes, **les meilleurs scores obtenus sur les images segment√©es** sont d√©tenus par le mod√®le des **K plus proches voisins**. L'accuracy et le F1-Score sont de **0.57-0.58**. De fa√ßon globale, les r√©sultats sont beaucoup moins bon sur les images apr√®s segmentation.")

st.write("**On peut toutefois noter que les plaquettes sont correctement class√©es √† 96%**, elles sont donc aussi bien class√©es (m√™me un peu mieux, s√ªrement d√ª √† la variabilit√© du jeu de test) que pour les mod√®les entra√Æn√©s sur des images non-segment√©es.")

knn_seg = Image.open('streamlit/knn_seg.png')
st.image(knn_seg)

with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le de r√©gression logistique"):
    lr_seg = Image.open('streamlit/lr_seg.png')
    st.image(lr_seg)
with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le SVM"):
    svm_seg = Image.open('streamlit/svm_seg.png')
    st.image(svm_seg)
with st.expander("Afficher/Cacher la matrice de confusion et le rapport de classification du mod√®le Random Forest"):
    rf_seg = Image.open('streamlit/rf_seg.png')
    st.image(rf_seg)
